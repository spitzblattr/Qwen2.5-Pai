#!/bin/bash
set -e  
ENV=$1
export PYTHONWARNINGS="ignore::FutureWarning"
export CUDA_DEVICE_MAX_CONNECTIONS=1
export NVTE_FLASH_ATTN=1
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
#export UB_SKIPMC=1      # å¦‚æœæœ‰ AssertionError: CUDA device, driver and/or toolkit version does not support comm+GEMM overlap with CUDA Multicast. Launch app with UB_SKIPMC=1 to try CUDA IPC instead.
export PYTHONPATH=/workspace/Pai-Megatron-Patch-0.10.3:/workspace/Pai-Megatron-Patch-0.10.3/Megatron-LM-core_r0.11.1:$PYTHONPATH   


# --------------------------------------------------------
IS_INITIAL_RUN=false    # ğŸš© # æ˜¯å¦ä¸ºé¦–æ¬¡è®­ç»ƒ
TRAIN_OR_CONVERT_CKPT=convert    # ğŸš© # â€œtrainâ€ | â€œconvertâ€ï¼ˆä¸ä¼šè®­ç»ƒï¼Œåªæ˜¯è½¬æ¢æ£€æŸ¥ç‚¹ï¼‰
# åœ¨ convert å‰ï¼ŒLOAD_CHECKPOINT_PATH ä¸‹éœ€è¦æœ‰config.jsonã€vocab.jsonã€tokenizer.jsonç­‰ï¼Œå¹¶ä¸”è¿˜è¦æœ‰ä¸€ä¸ªlatest_checkpointed_iteration.txt
# --------------------------------------------------------
DATASET_PATH=/mnt/public/datasets/max_len_2048/max_len_2048_text_document  # è¿™ä¸ªè·¯å¾„åé¢ä¼šç›´æ¥è¿½åŠ ".bin"/"idx"
LOAD_CHECKPOINT_PATH=/mnt/public/training_models/saved_ckpts                     
# â†‘â†‘ LOAD_CHECKPOINT_PATH ä¸‹å¿…é¡»è¦æœ‰config.jsonã€vocab.jsonã€tokenizer.jsonç­‰ï¼Œå¹¶ä¸”è¿˜è¦æœ‰ä¸€ä¸ªlatest_checkpointed_iteration.txt
SAVE_DIST_CHECKPOINT_PATH=/mnt/public/training_models/saved_ckpts
WANDB_SAVE_PATH=/home/wandb_logs   # Path to save the wandb results locally.
SAVE_TORCH_CHECKPOINT_PATH=/mnt/public/train_finished_models
# --------------------------------------------------------
# â­ï¸ â­ï¸ â­ï¸ï¼šè¯¥sectionä¸‹æ‰€æœ‰å‚æ•°éƒ½å¿…é¡»æ ¡éªŒ
# â­ï¸ï¼šè¯¥å•ä¸ªå‚æ•°å¿…é¡»æ ¡éªŒï¼ˆå¦‚æœæ²¡æœ‰è¿™ä¸ªæ ‡è®°ï¼Œå¹¶ä¸æ„å‘³ç€è¿™ä¸ªå‚æ•°ä¸€å®šä¸éœ€è¦æ ¡éªŒï¼Œåªæ˜¯å®ƒ*æˆ–è®¸å¯ä»¥*ä¸æ ¡éªŒï¼‰
# ğŸŒ™ï¼šè¿™ä¸ªå‚æ•°æ˜¯ PAI æ–°å¢çš„ï¼Œä¸æ˜¯åŸºç¡€ Megatron é‡Œçš„
# æ‰€æœ‰å‚æ•°è§ Pai-Megatron-Patch/Megatron-LM/megatron/training/arguments.py

DATA_ARGS=(
    --data-path $DATASET_PATH   # å…³äºæ··åˆæ¯”ä¾‹æ•°æ®é›†(blended dataset)çš„è§£é‡Šï¼šhttps://github.com/NVIDIA/Megatron-LM/issues/547
    --split 98,2,0 # â­ï¸ # è‹¥è¦æŒ‡å®šå•ç‹¬çš„validæ•°æ®é›†æ¥æºï¼Œä½¿ç”¨--valid-data-path
    --seq-length 2048   # â­ï¸ # Megatron-LM requires the input sequence length to be fixed and padded to the --seq-length
    --dataset MMAP  # ğŸŒ™  # "JSON-SFT"(æœªå¤„ç†çš„.jsonæ–‡ä»¶) or "MMAP"(å¤„ç†å®Œæ¯•çš„binå’Œidx)
)


# â­ï¸ â­ï¸ â­ï¸
DISTRIBUTED_ARGS=(
    --nproc_per_node 8
    --nnodes 1
    --node_rank 0 
    --master_addr localhost
    --master_port 22222
)

# â­ï¸ â­ï¸ â­ï¸
GPT_MODEL_CONFIGJSON_ARGS=(
    --num-layers 48
    --hidden-size 5120 
    --num-attention-heads 40
    --ffn-hidden-size 13824   
    --max-position-embeddings 131072
    --group-query-attention 
    --num-query-groups 8      
    --normalization RMSNorm 
    --norm-epsilon 1e-5    
    --extra-vocab-size 421 
    --untie-embeddings-and-output-weights 
    # --use-cpu-initialization 
)
# â­ï¸ â­ï¸ â­ï¸
GPT_MODEL_ADDITIONAL_ARGS=(
    --swiglu  
    --position-embedding-type rope  
    --disable-bias-linear # å…ˆå»é™¤æ‰€æœ‰çº¿æ€§å±‚çš„ bias
    --add-qkv-bias   # å†åœ¨ q,k,v_proj å±‚æ·»åŠ  bias
    --rotary-base 1000000    # Base to use for rotary positional embeddings. é»˜è®¤ä¸º10000
    --max-position-embeddings 32768    
    --rotary-percent 1.0   
    --rotary-seq-len-interpolation-factor 1 
    --patch-tokenizer-type Qwen2Tokenizer # ğŸŒ™ 
)


TRAINING_ARGS=(
    --bf16  # â­ï¸  
    --micro-batch-size 2 # â­ï¸ 
    --global-batch-size 16 # â­ï¸ # should be a multiple of micro-batch-size times data-parallel-sizeã€‚å½“æ˜¾å¼æŒ‡å®šäº† --global-batch-size æ—¶ï¼ŒMegatron ä¼šæ ¹æ®æ­¤å€¼è‡ªåŠ¨æ¨æ–­ num_micro_batches çš„å¤§å°
    --weight-decay 0.01  
    --init-method-std 0.02
    --clip-grad 1.0 
    --lr 6.5e-5       # â­ï¸
    --min-lr 2.5e-6   # â­ï¸
    --lr-warmup-iters 0
    --lr-decay-style cosine 
    #--lr-decay-iters: If None defaults to `--train-iters`
    --attention-dropout 0.0     # é»˜è®¤å¯ç”¨å¹¶ä¸º0.1
    --hidden-dropout 0.0    # é»˜è®¤å¯ç”¨å¹¶ä¸º0.1
    --calculate-per-token-loss    # ğŸ¤”
    --train-mode finetune  # â­ï¸ğŸŒ™  # type=str, help="pretrain or finetune" è¯¥å‚æ•°å½±å“ megatron_patch/template/helper.py ä¸­çš„ get_batch å‡½æ•°
)
num_epoches=3   # â­ï¸
num_training_samples=154678    # â­ï¸ # è‡ªè¡ŒæŸ¥çœ‹
train_iters=$(( num_epoches * num_training_samples / ${TRAINING_ARGS[4]} ))    # TRAINING_ARGS[4]æ˜¯--global-batch-size
TRAINING_ARGS+=(
    --train-iters $train_iters   
)


MODEL_PARALLEL_ARGS=(
	--tensor-model-parallel-size 2   # â­ï¸
	--pipeline-model-parallel-size 2  # â­ï¸
    --recompute-activations  # åœ¨å¤šæ•°æƒ…å†µä¸‹éƒ½åº”è¯¥å¯ç”¨ï¼Œé™¤éè®­ç»ƒå†…å­˜éå¸¸æœ‰é™
    --use-distributed-optimizer   # æ˜¯å¦ä½¿ç”¨Megatronç‰ˆZero-1ä¼˜åŒ–å™¨: , action='store_true'
    # 2025.3.24: Megatron-LM æ­£åœ¨æ·»åŠ  pai çš„ hybridadam
    # ç›¸å…³ä»£ç åŠå¦‚ä½•å¯ç”¨ cpu offloadï¼šhttps://github.com/NVIDIA/Megatron-LM/commit/60007c93d3aad8ce5fcca8c60267220e22f35b45#diff-f4b11f68d40efd8e51059784591dd551fe305f3640f09a99f11de599c6a58a79
    # --optimizer hybridadam    # ğŸŒ™ ç›¸å…³ä»£ç ï¼šhttps://github.com/alibaba/Pai-Megatron-Patch/pull/298/files (åªå­˜åœ¨äºPAI-Megatron-LM-240718åˆ†æ”¯)
    # --optimizer-offload-policy auto     # ğŸŒ™
)
# if --tensor-model-parallel-size > 1
if [ ${MODEL_PARALLEL_ARGS[1]} -gt 1 ]; then
    MODEL_PARALLEL_ARGS+=(
        # å…³äº sequence-parallel å’Œ context-parallel çš„ä»‹ç»ï¼šhttps://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html
        --sequence-parallel  # When --sequence-parallel is used, sequence_len must be a multiple of --tensor-parallel.
        --context-parallel-size 1    # Degree of context parallelism. é»˜è®¤ä¸º1.
        --tp-comm-overlap  # å¦‚æœTP>1ï¼Œåˆ™å¯ç”¨overlapç›¸å…³å‚æ•°
        --overlap-grad-reduce
        --overlap-param-gather
    )
fi
# if --pipeline-model-parallel-size > 1
if [ ${MODEL_PARALLEL_ARGS[3]} -gt 1 ]; then
    MODEL_PARALLEL_ARGS+=(
        # Enable p2p comm overlap when PP > 1 by setting num_layers_per_virtual_pipeline_stage.
        # --num-layers-per-virtual-pipeline-stage 1
        # â¬†è¦å¯ç”¨è¿™ä¸ªå‚æ•°ï¼Œéœ€è¦ä¿®æ”¹ Pai-Megatron-Patch-0.10.3/toolkits/model_checkpoints_convertor/qwen/hf2mcore_qwen2_dense_and_moe_gqa.py é‡Œçš„ç›¸å…³å‡½æ•°
        # å°è¯•å‚è€ƒ pai ä»“åº“é‡Œçš„ hf2mcore_qwen2.5_vl.py æ”¹äº†ä¸€ä¸‹ï¼Œå¤±è´¥ï¼ˆæ¨¡å‹å„å±‚åˆ’åˆ†çœ‹èµ·æ¥æ²¡é—®é¢˜ä½†losså¢å¤§ï¼‰ï¼Œæ‰¾ä¸å‡ºåŸå› ï¼Œæš‚æ—¶æç½®ä¸€ä¸‹
    )
fi


EVAL_LOGGING_AND_SAVE_ARGS=(
    --save-interval 100 # â­ï¸
    --eval-iters 50    # Number of iterations to run for evaluation validation/test for. default=100
    --eval-interval 100  # â­ï¸ # Interval between running evaluation on validation set. default=1000
    --save $SAVE_DIST_CHECKPOINT_PATH 
    --load $LOAD_CHECKPOINT_PATH 
    --exit-on-missing-checkpoint    # å¦‚æœæ‰¾ä¸åˆ°--loadä¸­çš„è·¯å¾„ï¼Œç›´æ¥é€€å‡º
    --auto-detect-ckpt-format   # æ¯æ¬¡ï¼ˆé‡æ–°æˆ–ç»§ç»­ï¼‰è®­ç»ƒå‰ï¼Œè‡ªåŠ¨æ£€æŸ¥$LOAD_CHECKPOINT_PATH çš„ checkpoint æ˜¯åŸå§‹torchæ ¼å¼è¿˜æ˜¯distcpæ ¼å¼
    
    --log-interval 100    
    --log-throughput   # If set, calculate and log throughput per GPU.
)
if [ ${IS_INITIAL_RUN} = true ]; then
    EVAL_LOGGING_AND_SAVE_ARGS+=(
        --no-load-optim   # When start initial training, specify `--no-load-optim --finetune` to make sure the optimizer state is NOT loaded from the pretrained GPT model so the continued pretraining is from a clean start. But, after the first run, you should launch without`--no-load-optim --finetune` to make sure the optimizer state is correctly loaded from your last job.
        --no-load-rng 
    )
fi
if [ $TRAIN_OR_CONVERT_CKPT = "train" ]; then
    EVAL_LOGGING_AND_SAVE_ARGS+=(
        --async-save   # Apply async checkpointing save. Currently works only with `torch_dist` distributed checkpoint format.
        # ä¸éœ€è¦æŒ‡å®š wandb çš„ team(shsfcx)ï¼Œè¿™ä¼šåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œè„šæœ¬æ—¶æ‰‹åŠ¨è®©ä½ è¾“å…¥
        --wandb-project spec_decode   # â­ï¸
        --wandb-exp-name qwen-sft  # â­ï¸ 
        --wandb-save-dir $WANDB_SAVE_PATH 
    )
elif [ $TRAIN_OR_CONVERT_CKPT = "convert" ]; then
    # å‚è€ƒ https://github.com/NVIDIA/Megatron-LM/issues/1266
    echo "æ­£åœ¨å°† $LOAD_CHECKPOINT_PATH ä¸­çš„æœ€æ–°æ£€æŸ¥ç‚¹ä» torch_dist è½¬æ¢åˆ° torch æ ¼å¼ï¼Œå¹¶ä¿å­˜è‡³ $SAVE_TORCH_CHECKPOINT_PATH" 
    EVAL_LOGGING_AND_SAVE_ARGS+=(
        --ckpt-convert-format torch  
        --ckpt-convert-save $SAVE_TORCH_CHECKPOINT_PATH
    )
fi


torchrun ${DISTRIBUTED_ARGS[@]} /workspace/Pai-Megatron-Patch-0.10.3/examples/qwen2/pretrain_qwen.py \
    ${DATA_ARGS[@]} \
    ${MODEL_PARALLEL_ARGS[@]} \
    ${GPT_MODEL_CONFIGJSON_ARGS[@]} \
    ${GPT_MODEL_ADDITIONAL_ARGS[@]} \
    ${TRAINING_ARGS[@]} \
    ${EVAL_LOGGING_AND_SAVE_ARGS[@]} \

set +x


<<'EOF'

ã€ï¼Ÿã€‘
è‡ªä»Megatron-core 0.11.0, ä¿å­˜æ£€æŸ¥ç‚¹çš„æ—¶å€™å°±ä¼šå‡ºç°
[WARNING  | megatron.core.dist_checkpointing.validation]: There is difference in the common state dict in different ranks. The differences are {6: ([('optimizer', 'optimizer', 'param_groups', 1, 'step')], [], []), 7: ([('optimizer', 'optimizer', 'param_groups', 1, 'step')], [], [])}
[WARNING  | megatron.core.dist_checkpointing.validation]: There is difference in the common state dict in different ranks. The differences are {6: ([], [], [(('optimizer', 'optimizer', 'param_groups', 1, 'step'), <class 'int'>, <class 'int'>)]), 7: ([], [], [(('optimizer', 'optimizer', 'param_groups', 1, 'step'), <class 'int'>, <class 'int'>)])}
ä¼¼ä¹æ˜¯optimizeré‡Œå¤šäº†ä¸€ä¸ªstepå­—æ®µå¼•èµ·çš„
ä¸å½±å“è®­ç»ƒå’Œä¿å­˜/åŠ è½½æ£€æŸ¥ç‚¹



EOF